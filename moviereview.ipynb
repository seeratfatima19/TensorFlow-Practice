{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrApfAZ8VrJ8Me3QO7RvWz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seeratfatima19/TensorFlow-Practice/blob/main/moviereview.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Bohzib_nUxxQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = keras.datasets.imdb\n",
        "(train_data,train_labels),(test_data,test_labels)= data.load_data(num_words=88000)"
      ],
      "metadata": {
        "id": "ocKJRBS6ViVa"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index= data.get_word_index()\n",
        "\n",
        "word_index={k:(v+3) for k,v in word_index.items()}\n",
        "word_index[\"<PAD>\"]=0\n",
        "word_index[\"<START>\"]=1\n",
        "word_index[\"<UNK>\"]=2\n",
        "word_index[\"<UNUSED>\"]=3\n",
        "\n",
        "reverse_word_index=dict([(value,key) for (key,value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "  return \" \".join([reverse_word_index.get(i,'?') for i in text])\n",
        "\n",
        "\n",
        "#checking decode function:\n",
        "\n",
        "print(decode_review(test_data[6]))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDQ34lda2BRe",
        "outputId": "7701115f-7f2d-49f5-ea28-fa068f8865df"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the steps are filled with hundreds of extras rapid and dramatic violence is always suggested and not explicit yet the visual images of the deaths of a few will last in the minds of the viewer forever br br the angular shots of marching boots and legs descending the steps are cleverly accentuated with long menacing shadows from a sun at the top of the steps the pace of the sequence is deliberately varied between the marching soldiers and a few civilians who summon up courage to beg them to stop a close up of a woman's face frozen in horror after being struck by a soldier's sword is the direct antecedent of the bank teller in bonnie in clyde and gives a lasting impression of the horror of the czarist regime br br the death of a young mother leads to a baby carriage careening down the steps in a sequence that has been copied by hitchcock in foreign correspondent by terry gilliam in brazil and brian depalma in the untouchables this sequence is shown repeatedly from various angles thus drawing out what probably was only a five second event br br potemkin is a film that the revolutionary spirit celebrates it for those already committed and it for the unconverted it seethes of fire and roars with the senseless injustices of the decadent czarist regime its greatest impact has been on film students who have borrowed and only slightly improved on techniques invented in russia several generations ago\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data= keras.preprocessing.sequence.pad_sequences(train_data, value=word_index[\"<PAD>\"],padding=\"post\",maxlen=250)\n",
        "test_data= keras.preprocessing.sequence.pad_sequences(test_data, value=word_index[\"<PAD>\"],padding=\"post\",maxlen=250)\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(88000,16))\n",
        "model.add(keras.layers.GlobalAveragePooling1D())\n",
        "model.add(keras.layers.Dense(16,activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(1,activation=\"sigmoid\"))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "x_val= train_data[:10000]\n",
        "x_train= train_data[1000:]\n",
        "\n",
        "y_val= train_labels[:10000]\n",
        "y_train= train_labels[1000:]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDwwWF_33Qtj",
        "outputId": "6de5127a-b854-470b-bb1e-21f717a66fe5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, None, 16)          1408000   \n",
            "                                                                 \n",
            " global_average_pooling1d_2   (None, 16)               0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,408,289\n",
            "Trainable params: 1,408,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fitModel = model.fit(x_train,y_train,epochs=40, batch_size=512, validation_data=(x_val,y_val), verbose=1 )\n",
        "results=model.evaluate(test_data,test_labels)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EfjDi9NIZUF",
        "outputId": "4dfc0737-f5e9-4fa4-bf2c-2ad5915d2ced"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "47/47 [==============================] - 3s 44ms/step - loss: 0.6909 - accuracy: 0.6052 - val_loss: 0.6866 - val_accuracy: 0.7533\n",
            "Epoch 2/40\n",
            "47/47 [==============================] - 2s 37ms/step - loss: 0.6767 - accuracy: 0.7567 - val_loss: 0.6621 - val_accuracy: 0.7517\n",
            "Epoch 3/40\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 0.6369 - accuracy: 0.7883 - val_loss: 0.6060 - val_accuracy: 0.8030\n",
            "Epoch 4/40\n",
            "47/47 [==============================] - 2s 42ms/step - loss: 0.5676 - accuracy: 0.8220 - val_loss: 0.5273 - val_accuracy: 0.8291\n",
            "Epoch 5/40\n",
            "47/47 [==============================] - 2s 39ms/step - loss: 0.4858 - accuracy: 0.8485 - val_loss: 0.4467 - val_accuracy: 0.8586\n",
            "Epoch 6/40\n",
            "47/47 [==============================] - 3s 58ms/step - loss: 0.4103 - accuracy: 0.8725 - val_loss: 0.3782 - val_accuracy: 0.8847\n",
            "Epoch 7/40\n",
            "47/47 [==============================] - 2s 35ms/step - loss: 0.3496 - accuracy: 0.8912 - val_loss: 0.3255 - val_accuracy: 0.8996\n",
            "Epoch 8/40\n",
            "47/47 [==============================] - 2s 35ms/step - loss: 0.3034 - accuracy: 0.9030 - val_loss: 0.2857 - val_accuracy: 0.9105\n",
            "Epoch 9/40\n",
            "47/47 [==============================] - 2s 36ms/step - loss: 0.2673 - accuracy: 0.9139 - val_loss: 0.2544 - val_accuracy: 0.9222\n",
            "Epoch 10/40\n",
            "47/47 [==============================] - 2s 35ms/step - loss: 0.2384 - accuracy: 0.9243 - val_loss: 0.2292 - val_accuracy: 0.9292\n",
            "Epoch 11/40\n",
            "47/47 [==============================] - 2s 35ms/step - loss: 0.2144 - accuracy: 0.9326 - val_loss: 0.2078 - val_accuracy: 0.9359\n",
            "Epoch 12/40\n",
            "47/47 [==============================] - 2s 42ms/step - loss: 0.1938 - accuracy: 0.9389 - val_loss: 0.1901 - val_accuracy: 0.9410\n",
            "Epoch 13/40\n",
            "47/47 [==============================] - 2s 52ms/step - loss: 0.1761 - accuracy: 0.9460 - val_loss: 0.1744 - val_accuracy: 0.9459\n",
            "Epoch 14/40\n",
            "47/47 [==============================] - 2s 49ms/step - loss: 0.1606 - accuracy: 0.9520 - val_loss: 0.1610 - val_accuracy: 0.9518\n",
            "Epoch 15/40\n",
            "47/47 [==============================] - 2s 38ms/step - loss: 0.1462 - accuracy: 0.9574 - val_loss: 0.1487 - val_accuracy: 0.9563\n",
            "Epoch 16/40\n",
            "47/47 [==============================] - 2s 42ms/step - loss: 0.1339 - accuracy: 0.9621 - val_loss: 0.1378 - val_accuracy: 0.9585\n",
            "Epoch 17/40\n",
            "47/47 [==============================] - 2s 35ms/step - loss: 0.1225 - accuracy: 0.9664 - val_loss: 0.1281 - val_accuracy: 0.9629\n",
            "Epoch 18/40\n",
            "47/47 [==============================] - 2s 49ms/step - loss: 0.1121 - accuracy: 0.9703 - val_loss: 0.1192 - val_accuracy: 0.9661\n",
            "Epoch 19/40\n",
            "47/47 [==============================] - 3s 63ms/step - loss: 0.1028 - accuracy: 0.9730 - val_loss: 0.1119 - val_accuracy: 0.9680\n",
            "Epoch 20/40\n",
            "47/47 [==============================] - 2s 46ms/step - loss: 0.0945 - accuracy: 0.9760 - val_loss: 0.1044 - val_accuracy: 0.9708\n",
            "Epoch 21/40\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 0.0872 - accuracy: 0.9781 - val_loss: 0.0985 - val_accuracy: 0.9719\n",
            "Epoch 22/40\n",
            "47/47 [==============================] - 2s 35ms/step - loss: 0.0799 - accuracy: 0.9812 - val_loss: 0.0923 - val_accuracy: 0.9742\n",
            "Epoch 23/40\n",
            "47/47 [==============================] - 2s 35ms/step - loss: 0.0739 - accuracy: 0.9830 - val_loss: 0.0872 - val_accuracy: 0.9762\n",
            "Epoch 24/40\n",
            "47/47 [==============================] - 2s 34ms/step - loss: 0.0680 - accuracy: 0.9847 - val_loss: 0.0823 - val_accuracy: 0.9771\n",
            "Epoch 25/40\n",
            "47/47 [==============================] - 2s 34ms/step - loss: 0.0628 - accuracy: 0.9860 - val_loss: 0.0779 - val_accuracy: 0.9783\n",
            "Epoch 26/40\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.0578 - accuracy: 0.9872 - val_loss: 0.0741 - val_accuracy: 0.9788\n",
            "Epoch 27/40\n",
            "47/47 [==============================] - 2s 47ms/step - loss: 0.0533 - accuracy: 0.9884 - val_loss: 0.0708 - val_accuracy: 0.9798\n",
            "Epoch 28/40\n",
            "47/47 [==============================] - 2s 34ms/step - loss: 0.0494 - accuracy: 0.9900 - val_loss: 0.0687 - val_accuracy: 0.9807\n",
            "Epoch 29/40\n",
            "47/47 [==============================] - 2s 36ms/step - loss: 0.0455 - accuracy: 0.9912 - val_loss: 0.0651 - val_accuracy: 0.9815\n",
            "Epoch 30/40\n",
            "47/47 [==============================] - 2s 43ms/step - loss: 0.0420 - accuracy: 0.9923 - val_loss: 0.0622 - val_accuracy: 0.9826\n",
            "Epoch 31/40\n",
            "47/47 [==============================] - 2s 47ms/step - loss: 0.0389 - accuracy: 0.9932 - val_loss: 0.0599 - val_accuracy: 0.9837\n",
            "Epoch 32/40\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.0360 - accuracy: 0.9939 - val_loss: 0.0580 - val_accuracy: 0.9844\n",
            "Epoch 33/40\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 0.0335 - accuracy: 0.9949 - val_loss: 0.0563 - val_accuracy: 0.9853\n",
            "Epoch 34/40\n",
            "47/47 [==============================] - 3s 66ms/step - loss: 0.0311 - accuracy: 0.9950 - val_loss: 0.0546 - val_accuracy: 0.9857\n",
            "Epoch 35/40\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 0.0287 - accuracy: 0.9960 - val_loss: 0.0533 - val_accuracy: 0.9863\n",
            "Epoch 36/40\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 0.0267 - accuracy: 0.9961 - val_loss: 0.0523 - val_accuracy: 0.9863\n",
            "Epoch 37/40\n",
            "47/47 [==============================] - 3s 68ms/step - loss: 0.0250 - accuracy: 0.9966 - val_loss: 0.0513 - val_accuracy: 0.9870\n",
            "Epoch 38/40\n",
            "47/47 [==============================] - 2s 38ms/step - loss: 0.0231 - accuracy: 0.9967 - val_loss: 0.0501 - val_accuracy: 0.9869\n",
            "Epoch 39/40\n",
            "47/47 [==============================] - 2s 42ms/step - loss: 0.0215 - accuracy: 0.9969 - val_loss: 0.0493 - val_accuracy: 0.9872\n",
            "Epoch 40/40\n",
            "47/47 [==============================] - 2s 42ms/step - loss: 0.0202 - accuracy: 0.9973 - val_loss: 0.0486 - val_accuracy: 0.9876\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4077 - accuracy: 0.8666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55RhIbDsJb1V",
        "outputId": "0571bf08-8f8d-4379-80e6-6e074f53b978"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.40773090720176697, 0.8666399717330933]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"review.h5\")"
      ],
      "metadata": {
        "id": "LHk2xIfpJsKl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HHTBD71WLHzt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}